<h1 align="middle">Проект по реализации <b>генеративной модели (CycleGAN)</b>.</h1>
<ul>
  <li><h4>Выполнил: Мартынов Владислав</h4></li>
  <li><h4>Поток: Продвинутый</h4></li>
  <li><h4>StepikID: 596247708</h4></li>
  <li><h4>GitHub: <a href=""https://github.com/VladMartinov>VladMartinov</a></h4></li>
</ul>
<h2 align="middle">Решаемая задача:</h2>
<ul>
  <li><h4>Monet2Photo</h4></li>
  <li><h4>Photo2Anime (Comming soon)</h4></li>
</ul>

<h2 align="middle">Пояснение:</h2>
<p>В данной проекте была реализована задача стилизации из обычной фотографии в монет и обратно при помощи возможностей Cycle GAN. А именно была решена задача Monet2Photo.</p>

<h2 align="middle">Кратко про модели и обучение:</h2>
<p>Все модели были основаны на основной документации и слегка модернезированы. Генераторы состоят из 9-и residual-блоков и down/up convolution layears, а так же активацией ReLU.</p>
<p>Дискриминаторы же в свою очередь состоит из Instance Block's а так же convolution layears, активация применяется LeakyReLU, а на выходе применяется sigmoid (архитектура напоминающая PathGAN).</p>
<p>Так же был реализован дополнительный буфер для дискриминатора (количество изображений в буфере = 50).</p>

<h2 align="middle">Процесс обучения.</h2>
<p>На вход подаются изображения размерностью 256 x 256. Выходные изображение будут иметь такую же размерность.</p>
<p>Присутствует возможность обучения уже как существующих моделей так и обучение новых. Так же можно сохронять прогресс после каждой эпохи (как изображений, так и моделей).</p>
<hr>
<p>Таким образом для обучения необходим датасет с изображениями 256 x 256 (другие не тестировались), желательно чтобы датасет был сбалансирован (не было такого, что допустим monet было в 2-а раза больше photo или наоборот).</p>
<p>На выходе у нас могут сохранятся изображения в ходе обучения, а так же весы моделей.</p>
<p>Пути к датасетам можно прописать в .ipynb файле где можно и настроить обучение (количество эпох, лямбды, пути к датасету и многое др.)</p>
<p>Итого. В репозитории находится 2-а файла .ipynb: для Kaggle и для Colab (Практически одинаковые, но имеют разницу в сохранении и получении данных. Возможности обучения на обычном ПК не было, поэтому обычные .py файлы не использовал). В них в самом начале можно настроить параметры обучения модели. Для удобства в Colab было реализовано автоматическое сохранение на Drive (в Kaggle это можно делать через Quick Save). Обязательно указывайте пути к файлам и куда сохранять результаты. В Kaggle был взян расчет на то, что у вас есть dataset (input файлы) из которого вы и берете картинки.</p>

<h2 align="middle">Примеры получившихся результатов:</h2>
<h4>Monet2Photo:</h4>

| Исходная:     | Результата преобразования:  |
| ------------- | --------------------------- |
| ![image](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/b57d97e3-3c4f-4182-b5ff-2eaa446ca589) | ![image](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/7e580729-b637-4266-8dac-ca1ac3b94368) |
| ![image](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/f994e935-e3fd-437d-8d49-3dd64adc88c9) | ![image](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/894e5560-bb9b-4e1d-8864-9b1b0a048d01) |

<h4>Photo2Anime (Comming soon):</h4>

<hr>
<h2>Telegram BOT:</h2>
<p>Чтобы использовать телеграм бота необходибо скачать папку "CycleGAN_Bot" в котором будет находится 2-а файла: файл с модель генератора и код запуска бота. В коде уже заранее установлен API к боту <a href="https://t.me/DLCycleGANMonetBot">DLCycleGANMonetBot</a>. После скачивания папки с 2-мя файлами к ним необходимо поместить файл с весами генератора (должен называться "genm.pth.tar"). Далее мы запускаем через консоль (Anaconda Prompt, ...) файл "CycleGanTelegram.py" через команду - python CycleGanTelegram.py . Перед этим убедитесь, что вы находитесь в данной папке. После запуска бота мы можем его тестировать. Можно отпавить ему любое изображение (желательно 256x256, т.к. он автоматически делает ресайз на этот размер) и в итоге он отправит сообщением готовый результат.</p>
<p>Пример генерации:</p>

![image](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/6c00c8d2-857b-415d-9cd5-33e35a66d1e4)

<hr>
<h2>Используемая литература:</h2>
<ol>
  <li><h4><a href="https://arxiv.org/pdf/1703.10593.pdf">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.</a></h4></li>
  <li><h4><a href="https://www.youtube.com/watch?v=5jziBapziYE&list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va&index=8">CycleGAN Paper Walkthrough.</a></h4></li>
  <li><h4><a href="https://hannibunny.github.io/mlbook/gan/GAN.html">HOCHSCHULE DER MEDIEN. Generative Adversarial Nets (GAN)</a></h4></li>
  <li><h4><a href="https://nn.labml.ai/gan/cycle_gan/index.html">labml.ai. Cycle GAN</a></h4></li>
  <li><h4><a href="https://blog.paperspace.com/unpaired-image-to-image-translations-with-cycle-gans/">Unpaired Image to Image Translations with Cycle GANs</a></h4></li>
</ol>
<h2>Ссылка на весы и примеры фото в процессе обучения:</h2>
<ul>
  <li><h4><a href="https://drive.google.com/drive/folders/1OJRgLQmvXJTDdMa-OWqW0_k0EuaMxK7c?usp=sharing">Папка на Google Drive со всеми файлами и весами.</a></h4></li>
  <li><h4><a href="https://www.kaggle.com/code/vladmartinov/cyclegan-dd">Kaggle notebook с разными версиями (разные количество эпох обучения с сохраненными весами).</a></h4></li>
</ul>
<hr>
<p>p.s.: Подводя итоги финального задания, хотелсь бы сказать некоторое свое мнение. Разница в результате при обучении на дисбалансном датасете и нормальном имеется. Я обучал около 220 эпох для получения приведённого результата выше, генератор с 9 res. блоками и датасетом с небольшим дисбалансом (1100 монет и 1350 обычных). 1 эпоха - 5 мин. на Kaggle (gpu - TPU). Во втором эксперемнте я обучил 200 эпох на идентичной модели генератора но с датасетом с большим дисбалансом (1100 монет и 6000 обычных). 1 эпоха - 25 мин. на Colab (gpu - TPU). Итого разница между этими результатми колоссальная, модель с дисбалансом имеет силльные проблемы с пятнами, да и просто искажениями. Итого могу сказать, что для 9 res. блоков можно еще пообучать, т.к. это достаточно глубокая модель (можно было взять с 6 блоками). <br /> Ниже покажу результат обучения 200 эпох дисбалансной модели и почему стоит следить на балансом модели (1-я картинка - наилучший результат; другие картинки - обычный результат):</p>

| ![monet_200](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/5ef98782-a224-47f0-96b0-17c47db6c85d) | ![monet_1000](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/cf3b3e76-b536-4da9-88d5-7b2d1f6e2ab0) | ![monet_5400](https://github.com/VladMartinov/DL.CycleGAN/assets/92305802/edc17629-8c04-406b-9223-3906a2fa1642) |
